{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1692cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.table import Table\n",
    "from matplotlib import colors\n",
    "plt.style.use(\"ggplot\")\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "\n",
    "epsilon = 0.1 #the percentage of time when we should take the best action (instead of a random action)\n",
    "discount_factor = 0.9 #discount factor for future rewards\n",
    "learning_rate = 0.9 #the rate at which the AI agent should learn\n",
    "num_episode = 1000\n",
    "\n",
    "NUM_ACTION = 4\n",
    "actions = ['up', 'right', 'down', 'left']\n",
    "\n",
    "# Setup environment\n",
    "env_row = 4\n",
    "env_column = 5\n",
    "state_values = np.zeros((env_row, env_column))\n",
    "env_reward = np.full((env_row, env_column), -1)\n",
    "env_reward[env_row - 1, 1:int(env_column - 1)] = -100\n",
    "state_values[env_row - 1, 1:int(env_column - 1)] = -100\n",
    "print(env_reward)\n",
    "print(state_values)\n",
    "# print()\n",
    "# state_values[2, 2] = 1\n",
    "# a = state_values[2][2]\n",
    "# a = 2\n",
    "# print(state_values)\n",
    "# for i in range (10):\n",
    "#   print(explore(3, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploit(current_row_index, current_column_index):\n",
    "  has_max = False\n",
    "  if current_row_index > 0:\n",
    "    if not has_max:\n",
    "      has_max = True\n",
    "      max = state_values[current_row_index - 1][current_column_index]\n",
    "      new_row_index, new_column_index = current_row_index - 1, current_column_index\n",
    "    else:\n",
    "      if state_values[current_row_index - 1][current_column_index] > max:\n",
    "        max = state_values[current_row_index - 1][current_column_index]\n",
    "        new_row_index, new_column_index = current_row_index - 1, current_column_index\n",
    "\n",
    "  if current_row_index < env_row - 1:\n",
    "    if not has_max:\n",
    "      has_max = True\n",
    "      max = state_values[current_row_index + 1][current_column_index]\n",
    "      new_row_index, new_column_index = current_row_index + 1, current_column_index\n",
    "    else:\n",
    "      if state_values[current_row_index + 1][current_column_index] > max:\n",
    "        max = state_values[current_row_index + 1][current_column_index]\n",
    "        new_row_index, new_column_index = current_row_index + 1, current_column_index\n",
    "\n",
    "  if current_column_index > 0:\n",
    "    if not has_max:\n",
    "      has_max = True\n",
    "      max = state_values[current_row_index][current_column_index - 1]\n",
    "      new_row_index, new_column_index = current_row_index, current_column_index - 1\n",
    "    else:\n",
    "      if state_values[current_row_index][current_column_index - 1] > max:\n",
    "        max = state_values[current_row_index][current_column_index - 1]\n",
    "        new_row_index, new_column_index = current_row_index, current_column_index - 1\n",
    "\n",
    "  if current_column_index < env_column - 1:\n",
    "    if not has_max:\n",
    "      has_max = True\n",
    "      max = state_values[current_row_index][current_column_index + 1]\n",
    "      new_row_index, new_column_index = current_row_index, current_column_index + 1\n",
    "    else:\n",
    "      if state_values[current_row_index][current_column_index + 1] > max:\n",
    "        max = state_values[current_row_index][current_column_index + 1]\n",
    "        new_row_index, new_column_index = current_row_index, current_column_index + 1\n",
    "  return [new_row_index, new_column_index]\n",
    "\n",
    "def explore(current_row_index, current_column_index):\n",
    "  list_of_legal_move = list()\n",
    "  if current_row_index > 0:\n",
    "    list_of_legal_move.append([current_row_index - 1, current_column_index])\n",
    "  if current_row_index < env_row - 1:\n",
    "    list_of_legal_move.append([current_row_index + 1, current_column_index])\n",
    "  if current_column_index > 0:\n",
    "    list_of_legal_move.append([current_row_index, current_column_index - 1])\n",
    "  if current_column_index < env_column - 1:\n",
    "    list_of_legal_move.append([current_row_index, current_column_index + 1])\n",
    "  index = random.choice(range(len(list_of_legal_move)))\n",
    "  return list_of_legal_move[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7ded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_location():\n",
    "  return env_row - 1, 0\n",
    "\n",
    "def is_terminal_state(current_row_index, current_column_index):\n",
    "  assert current_row_index < env_row and current_column_index < env_column # Illegal location\n",
    "  if current_row_index == env_row - 1 and 0 < current_column_index < env_column:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def move_to_next_state(current_row_index, current_column_index, epsilon):\n",
    "  # e-greedy policy\n",
    "  if np.random.random() > epsilon:\n",
    "    return exploit(current_row_index, current_column_index)\n",
    "  else: #choose a random action\n",
    "    return explore(current_row_index, current_column_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(num_episode, epsilon, discount_factor, learning_rate):\n",
    "  start = timeit.default_timer()\n",
    "  list_of_marks = list()\n",
    "  for episode in range(num_episode):\n",
    "    sum_of_reward = 0\n",
    "    row_index, column_index = get_starting_location()\n",
    "    new_row_index, new_column_index = move_to_next_state(row_index, column_index, epsilon)\n",
    "    sum_of_reward += env_reward[row_index, column_index] + env_reward[new_row_index, new_column_index]\n",
    "\n",
    "    #continue taking actions  until we reach a terminal state\n",
    "    while not is_terminal_state(new_row_index, new_column_index):\n",
    "      old_row_index, old_column_index = row_index, column_index #store the old row and column indexes\n",
    "      row_index, column_index = new_row_index, new_column_index\n",
    "\n",
    "      new_row_index, new_column_index = move_to_next_state(row_index, column_index, epsilon)\n",
    "      #receive the reward for moving to the new state, and calculate the temporal difference\n",
    "      reward = env_reward[row_index, column_index]\n",
    "      old_state_value = state_values[old_row_index, old_column_index]\n",
    "      state_value = state_values[row_index, column_index]\n",
    "      temporal_difference = reward + (discount_factor * state_value) - old_state_value\n",
    "\n",
    "      #update the Q-value for the previous state and action pair\n",
    "      old_state_value = old_state_value + (learning_rate * temporal_difference)\n",
    "      # print(type(old_state_value))\n",
    "      # print(old_row_index, old_column_index)\n",
    "      # print(state_values[old_row_index, old_column_index])\n",
    "      state_values[old_row_index, old_column_index] = old_state_value\n",
    "      sum_of_reward += env_reward[new_row_index, new_column_index]\n",
    "    \n",
    "    list_of_marks.append(sum_of_reward)\n",
    "\n",
    "  end = timeit.default_timer()\n",
    "  print(f'Running in: {(end - start)*1000} ms')\n",
    "  return list_of_marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab1931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = 10\n",
    "list_of_marks = run(episode, 0.1, 0.9, 0.8)\n",
    "a = np.around(state_values, decimals=2, out=None)\n",
    "print(pd.DataFrame(a))\n",
    "print(list_of_marks)\n",
    "plt.plot(range(episode), list_of_marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4160ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ab418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
