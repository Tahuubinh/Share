{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153fac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "plt.style.use(\"ggplot\")\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.table import Table\n",
    "from matplotlib import colors\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "\n",
    "epsilon = 0.1 #the percentage of time when we should take the best action (instead of a random action)\n",
    "discount_factor = 0.9 #discount factor for future rewards\n",
    "learning_rate = 0.9 #the rate at which the AI agent should learn\n",
    "num_episode = 1000\n",
    "\n",
    "NUM_ACTION = 4\n",
    "actions = ['up', 'right', 'down', 'left']\n",
    "\n",
    "# Setup environment\n",
    "env_row = 4\n",
    "env_column = 5\n",
    "q_values = np.zeros((env_row, env_column, NUM_ACTION))\n",
    "env_reward = np.full((env_row, env_column), -1)\n",
    "env_reward[3, 1:4] = -100\n",
    "env_reward[3,0] = -1\n",
    "env_reward[3,4] = 1000\n",
    "print(env_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal_state(current_row_index, current_column_index):\n",
    "  assert current_row_index < env_row and current_column_index < env_column # Illegal location\n",
    "  if current_row_index == env_row - 1 and 0 < current_column_index < env_column:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def get_starting_location():\n",
    "  return env_row - 1, 0\n",
    "\n",
    "def get_next_action(current_row_index, current_column_index, epsilon):\n",
    "  # e-greedy policy\n",
    "  if np.random.random() > epsilon:\n",
    "    return np.argmax(q_values[current_row_index, current_column_index])\n",
    "  else: #choose a random action\n",
    "    return np.random.randint(4)\n",
    "\n",
    "def get_next_location(current_row_index, current_column_index, action_index):\n",
    "  new_row_index = current_row_index\n",
    "  new_column_index = current_column_index\n",
    "  if actions[action_index] == 'up' and current_row_index > 0:\n",
    "    new_row_index -= 1\n",
    "  elif actions[action_index] == 'right' and current_column_index < env_column - 1:\n",
    "    new_column_index += 1\n",
    "  elif actions[action_index] == 'down' and current_row_index < env_row - 1:\n",
    "    new_row_index += 1\n",
    "  elif actions[action_index] == 'left' and current_column_index > 0:\n",
    "    new_column_index -= 1\n",
    "  return new_row_index, new_column_index\n",
    "\n",
    "def get_shortest_path():\n",
    "    current_row_index, current_column_index = get_starting_location()\n",
    "    shortest_path = []\n",
    "    shortest_path.append([current_row_index, current_column_index])\n",
    "    #continue moving along the path until we reach the goal (i.e., the item packaging location)\n",
    "    while not is_terminal_state(current_row_index, current_column_index):\n",
    "      #get the best action to take\n",
    "      action_index = get_next_action(current_row_index, current_column_index, epsilon = 0)\n",
    "      #move to the next location on the path, and add the new location to the list\n",
    "      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n",
    "      shortest_path.append([current_row_index, current_column_index])\n",
    "      print([current_row_index, current_column_index], action_index)\n",
    "    return shortest_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92546c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_episode, epsilon, discount_factor, learning_rate):\n",
    "  start = timeit.default_timer()\n",
    "  for episode in range(num_episode):\n",
    "    row_index, column_index = get_starting_location()\n",
    "\n",
    "    #continue taking actions  until we reach a terminal state\n",
    "    while not is_terminal_state(row_index, column_index):\n",
    "      action_index = get_next_action(row_index, column_index, epsilon)\n",
    "      old_row_index, old_column_index = row_index, column_index #store the old row and column indexes\n",
    "      row_index, column_index = get_next_location(row_index, column_index, action_index)\n",
    "      \n",
    "      #receive the reward for moving to the new state, and calculate the temporal difference\n",
    "      reward = env_reward[row_index, column_index]\n",
    "      old_q_value = q_values[old_row_index, old_column_index, action_index]\n",
    "      temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n",
    "\n",
    "      #update the Q-value for the previous state and action pair\n",
    "      new_q_value = old_q_value + (learning_rate * temporal_difference)\n",
    "      q_values[old_row_index, old_column_index, action_index] = new_q_value\n",
    "\n",
    "  end = timeit.default_timer()\n",
    "  print(f'Training complete in: {(end - start)*1000} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545926f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(num_episode = 100, epsilon = 0.1, discount_factor = 0.99, learning_rate = 0.01)\n",
    "print(np.around(q_values, decimals=2, out=None))\n",
    "np.argmax(q_values[3, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7b3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = get_shortest_path()\n",
    "simulation = np.zeros((env_row, env_column))\n",
    "for i in path:\n",
    "  simulation[i[0], i[1]] = 1\n",
    "print(simulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1192ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.around(q_values, decimals=2, out=None))\n",
    "np.argmax(q_values[3, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eec384",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
